{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\choud\\anaconda3\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: keras in c:\\users\\choud\\anaconda3\\lib\\site-packages (3.7.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\choud\\anaconda3\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy in c:\\users\\choud\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\choud\\anaconda3\\lib\\site-packages (3.7.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\choud\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\choud\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\choud\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.28.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\choud\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: rich in c:\\users\\choud\\anaconda3\\lib\\site-packages (from keras) (13.5.2)\n",
      "Requirement already satisfied: namex in c:\\users\\choud\\anaconda3\\lib\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\choud\\anaconda3\\lib\\site-packages (from keras) (0.13.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\choud\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow keras opencv-python numpy matplotlib pandas scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 files belonging to 7 classes.\n",
      "Found 7178 files belonging to 7 classes.\n",
      "Emotion Labels: ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "train_dir = \"C:/MENATL_HEALTH/train\"\n",
    "test_dir = \"C:/MENATL_HEALTH/test\"\n",
    "\n",
    "# Load Train & Test dataset\n",
    "batch_size = 32\n",
    "img_size = (48, 48)\n",
    "\n",
    "train_ds = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"grayscale\"  # Convert images to grayscale\n",
    ")\n",
    "\n",
    "test_ds = image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"grayscale\"\n",
    ")\n",
    "\n",
    "# Class names (emotions)\n",
    "class_names = train_ds.class_names\n",
    "print(\"Emotion Labels:\", class_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\choud\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 35ms/step - accuracy: 0.2350 - loss: 2.7197 - val_accuracy: 0.3518 - val_loss: 1.6297\n",
      "Epoch 2/20\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 31ms/step - accuracy: 0.3400 - loss: 1.6646 - val_accuracy: 0.3902 - val_loss: 1.5574\n",
      "Epoch 3/20\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 31ms/step - accuracy: 0.3871 - loss: 1.5737 - val_accuracy: 0.4386 - val_loss: 1.4480\n",
      "Epoch 4/20\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 34ms/step - accuracy: 0.4118 - loss: 1.5061 - val_accuracy: 0.4320 - val_loss: 1.4546\n",
      "Epoch 5/20\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m703s\u001b[0m 784ms/step - accuracy: 0.4388 - loss: 1.4524 - val_accuracy: 0.4663 - val_loss: 1.3850\n",
      "Epoch 6/20\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 34ms/step - accuracy: 0.4609 - loss: 1.4090 - val_accuracy: 0.4791 - val_loss: 1.3679\n",
      "Epoch 7/20\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 33ms/step - accuracy: 0.4611 - loss: 1.3875 - val_accuracy: 0.4806 - val_loss: 1.3525\n",
      "Epoch 8/20\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 30ms/step - accuracy: 0.4793 - loss: 1.3459 - val_accuracy: 0.4925 - val_loss: 1.3315\n",
      "Epoch 9/20\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 31ms/step - accuracy: 0.4968 - loss: 1.3191 - val_accuracy: 0.4946 - val_loss: 1.3229\n",
      "Epoch 10/20\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 32ms/step - accuracy: 0.5000 - loss: 1.3086 - val_accuracy: 0.4958 - val_loss: 1.3212\n",
      "Epoch 11/20\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 33ms/step - accuracy: 0.5150 - loss: 1.2606 - val_accuracy: 0.5025 - val_loss: 1.3163\n",
      "Epoch 12/20\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 33ms/step - accuracy: 0.5257 - loss: 1.2407 - val_accuracy: 0.4926 - val_loss: 1.3376\n",
      "Epoch 13/20\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 33ms/step - accuracy: 0.5320 - loss: 1.2213 - val_accuracy: 0.4861 - val_loss: 1.3743\n",
      "Epoch 14/20\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2087s\u001b[0m 2s/step - accuracy: 0.5427 - loss: 1.1849 - val_accuracy: 0.5033 - val_loss: 1.3380\n",
      "Epoch 15/20\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 32ms/step - accuracy: 0.5509 - loss: 1.1665 - val_accuracy: 0.5145 - val_loss: 1.3155\n",
      "Epoch 16/20\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 30ms/step - accuracy: 0.5619 - loss: 1.1353 - val_accuracy: 0.4985 - val_loss: 1.3536\n",
      "Epoch 17/20\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 31ms/step - accuracy: 0.5743 - loss: 1.1125 - val_accuracy: 0.5131 - val_loss: 1.3394\n",
      "Epoch 18/20\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 33ms/step - accuracy: 0.5751 - loss: 1.0963 - val_accuracy: 0.5022 - val_loss: 1.3974\n",
      "Epoch 19/20\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 32ms/step - accuracy: 0.5930 - loss: 1.0709 - val_accuracy: 0.4971 - val_loss: 1.4465\n",
      "Epoch 20/20\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 34ms/step - accuracy: 0.5949 - loss: 1.0642 - val_accuracy: 0.4827 - val_loss: 1.4199\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Define CNN Model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation=\"relu\", input_shape=(48,48,1)),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Conv2D(64, (3,3), activation=\"relu\"),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Conv2D(128, (3,3), activation=\"relu\"),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    Dropout(0.5),  # Prevent overfitting\n",
    "    Dense(len(class_names), activation=\"softmax\")  # Output layer\n",
    "])\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(train_ds, validation_data=test_ds, epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "model.save(\"emotion_model.keras\")\n",
    "print(\"Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.4837 - loss: 1.4264\n",
      "Test Accuracy: 48.27%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_ds)\n",
    "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1301: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mrectangle(frame, (x, y), (x\u001b[38;5;241m+\u001b[39mw, y\u001b[38;5;241m+\u001b[39mh), (\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m255\u001b[39m,\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     33\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mputText(frame, emotion_label, (x, y\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m10\u001b[39m), cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m1\u001b[39m, (\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m255\u001b[39m,\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 35\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmotion Detection\u001b[39m\u001b[38;5;124m\"\u001b[39m, frame)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1301: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(\"emotion_model.h5\")\n",
    "\n",
    "# Load Haar Cascade for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5, minSize=(30,30))\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face = gray[y:y+h, x:x+w]  # Extract face\n",
    "        face = cv2.resize(face, (48,48))  # Resize to match model input\n",
    "        face = np.expand_dims(face, axis=0)  # Expand dims for batch\n",
    "        face = np.expand_dims(face, axis=-1) / 255.0  # Normalize\n",
    "\n",
    "        # Predict Emotion\n",
    "        prediction = model.predict(face)\n",
    "        emotion_label = class_names[np.argmax(prediction)]\n",
    "\n",
    "        # Draw bounding box and label\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0,255,0), 2)\n",
    "        cv2.putText(frame, emotion_label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "\n",
    "    cv2.imshow(\"Emotion Detection\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1295: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 49\u001b[0m\n\u001b[0;32m     46\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     48\u001b[0m cap\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m---> 49\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1295: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(\"emotion_model.h5\")\n",
    "\n",
    "# Load Haar Cascade for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Run for 10 frames (adjustable)\n",
    "for _ in range(10):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5, minSize=(30,30))\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face = gray[y:y+h, x:x+w]  # Extract face\n",
    "        face = cv2.resize(face, (48,48))  # Resize to match model input\n",
    "        face = np.expand_dims(face, axis=0)  # Expand dims for batch\n",
    "        face = np.expand_dims(face, axis=-1) / 255.0  # Normalize\n",
    "\n",
    "        # Predict Emotion\n",
    "        prediction = model.predict(face)\n",
    "        emotion_label = class_names[np.argmax(prediction)]\n",
    "\n",
    "        # Draw bounding box and label\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0,255,0), 2)\n",
    "        cv2.putText(frame, emotion_label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "\n",
    "    # Convert frame to RGB (for Matplotlib)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Display the image in Jupyter Notebook\n",
    "    plt.imshow(frame_rgb)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
